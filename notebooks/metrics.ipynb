{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, lit\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/11/05 08:45:56 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "22/11/05 08:45:57 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column<'domain'>\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute '_get_object_id'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn [4], line 27\u001B[0m\n\u001B[1;32m     21\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m domain\n\u001B[1;32m     23\u001B[0m \u001B[38;5;28mprint\u001B[39m(getdomain(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPython\u001B[39m\u001B[38;5;124m\"\u001B[39m)\u001B[38;5;241m.\u001B[39mdomain)\n\u001B[1;32m     25\u001B[0m df\u001B[38;5;241m.\u001B[39mselect(\n\u001B[1;32m     26\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlanguage\u001B[39m\u001B[38;5;124m\"\u001B[39m,\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124musers_count\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m---> 27\u001B[0m     \u001B[43mlit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mgetdomain\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mPython\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39malias(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdomain\u001B[39m\u001B[38;5;124m\"\u001B[39m))\n\u001B[1;32m     28\u001B[0m \u001B[38;5;28mprint\u001B[39m(df)\n\u001B[1;32m     29\u001B[0m \u001B[38;5;66;03m#\u001B[39;00m\n\u001B[1;32m     30\u001B[0m \u001B[38;5;66;03m# df2 = df.select(\u001B[39;00m\n\u001B[1;32m     31\u001B[0m \u001B[38;5;66;03m#     col(\"language\").alias(\"lang\")\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     37\u001B[0m \n\u001B[1;32m     38\u001B[0m \u001B[38;5;66;03m# print(df2)\u001B[39;00m\n",
      "File \u001B[0;32m~/dev/repo/hacking-spark-with-mongo/venv/lib/python3.8/site-packages/pyspark/sql/functions.py:137\u001B[0m, in \u001B[0;36mlit\u001B[0;34m(col)\u001B[0m\n\u001B[1;32m    126\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mlit\u001B[39m(col: Any) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Column:\n\u001B[1;32m    127\u001B[0m     \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    128\u001B[0m \u001B[38;5;124;03m    Creates a :class:`~pyspark.sql.Column` of literal value.\u001B[39;00m\n\u001B[1;32m    129\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    135\u001B[0m \u001B[38;5;124;03m    [Row(height=5, spark_user=True)]\u001B[39;00m\n\u001B[1;32m    136\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 137\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m col \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(col, Column) \u001B[38;5;28;01melse\u001B[39;00m \u001B[43m_invoke_function\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mlit\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcol\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/dev/repo/hacking-spark-with-mongo/venv/lib/python3.8/site-packages/pyspark/sql/functions.py:85\u001B[0m, in \u001B[0;36m_invoke_function\u001B[0;34m(name, *args)\u001B[0m\n\u001B[1;32m     83\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m SparkContext\u001B[38;5;241m.\u001B[39m_active_spark_context \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m     84\u001B[0m jf \u001B[38;5;241m=\u001B[39m _get_jvm_function(name, SparkContext\u001B[38;5;241m.\u001B[39m_active_spark_context)\n\u001B[0;32m---> 85\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m Column(\u001B[43mjf\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m)\n",
      "File \u001B[0;32m~/dev/repo/hacking-spark-with-mongo/venv/lib/python3.8/site-packages/py4j/java_gateway.py:1313\u001B[0m, in \u001B[0;36mJavaMember.__call__\u001B[0;34m(self, *args)\u001B[0m\n\u001B[1;32m   1312\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs):\n\u001B[0;32m-> 1313\u001B[0m     args_command, temp_args \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_build_args\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1315\u001B[0m     command \u001B[38;5;241m=\u001B[39m proto\u001B[38;5;241m.\u001B[39mCALL_COMMAND_NAME \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1316\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcommand_header \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1317\u001B[0m         args_command \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1318\u001B[0m         proto\u001B[38;5;241m.\u001B[39mEND_COMMAND_PART\n\u001B[1;32m   1320\u001B[0m     answer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgateway_client\u001B[38;5;241m.\u001B[39msend_command(command)\n",
      "File \u001B[0;32m~/dev/repo/hacking-spark-with-mongo/venv/lib/python3.8/site-packages/py4j/java_gateway.py:1283\u001B[0m, in \u001B[0;36mJavaMember._build_args\u001B[0;34m(self, *args)\u001B[0m\n\u001B[1;32m   1279\u001B[0m     new_args \u001B[38;5;241m=\u001B[39m args\n\u001B[1;32m   1280\u001B[0m     temp_args \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m   1282\u001B[0m args_command \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mjoin(\n\u001B[0;32m-> 1283\u001B[0m     [get_command_part(arg, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpool) \u001B[38;5;28;01mfor\u001B[39;00m arg \u001B[38;5;129;01min\u001B[39;00m new_args])\n\u001B[1;32m   1285\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m args_command, temp_args\n",
      "File \u001B[0;32m~/dev/repo/hacking-spark-with-mongo/venv/lib/python3.8/site-packages/py4j/java_gateway.py:1283\u001B[0m, in \u001B[0;36m<listcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m   1279\u001B[0m     new_args \u001B[38;5;241m=\u001B[39m args\n\u001B[1;32m   1280\u001B[0m     temp_args \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m   1282\u001B[0m args_command \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mjoin(\n\u001B[0;32m-> 1283\u001B[0m     [\u001B[43mget_command_part\u001B[49m\u001B[43m(\u001B[49m\u001B[43marg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpool\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m arg \u001B[38;5;129;01min\u001B[39;00m new_args])\n\u001B[1;32m   1285\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m args_command, temp_args\n",
      "File \u001B[0;32m~/dev/repo/hacking-spark-with-mongo/venv/lib/python3.8/site-packages/py4j/protocol.py:298\u001B[0m, in \u001B[0;36mget_command_part\u001B[0;34m(parameter, python_proxy_pool)\u001B[0m\n\u001B[1;32m    296\u001B[0m         command_part \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m;\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m+\u001B[39m interface\n\u001B[1;32m    297\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 298\u001B[0m     command_part \u001B[38;5;241m=\u001B[39m REFERENCE_TYPE \u001B[38;5;241m+\u001B[39m \u001B[43mparameter\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_object_id\u001B[49m()\n\u001B[1;32m    300\u001B[0m command_part \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    302\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m command_part\n",
      "File \u001B[0;32m~/dev/repo/hacking-spark-with-mongo/venv/lib/python3.8/site-packages/pyspark/sql/dataframe.py:1988\u001B[0m, in \u001B[0;36mDataFrame.__getattr__\u001B[0;34m(self, name)\u001B[0m\n\u001B[1;32m   1978\u001B[0m \u001B[38;5;124;03m\"\"\"Returns the :class:`Column` denoted by ``name``.\u001B[39;00m\n\u001B[1;32m   1979\u001B[0m \n\u001B[1;32m   1980\u001B[0m \u001B[38;5;124;03m.. versionadded:: 1.3.0\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1985\u001B[0m \u001B[38;5;124;03m[Row(age=2), Row(age=5)]\u001B[39;00m\n\u001B[1;32m   1986\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   1987\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcolumns:\n\u001B[0;32m-> 1988\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAttributeError\u001B[39;00m(\n\u001B[1;32m   1989\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m object has no attribute \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m, name)\n\u001B[1;32m   1990\u001B[0m     )\n\u001B[1;32m   1991\u001B[0m jc \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jdf\u001B[38;5;241m.\u001B[39mapply(name)\n\u001B[1;32m   1992\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m Column(jc)\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'DataFrame' object has no attribute '_get_object_id'"
     ]
    }
   ],
   "source": [
    "columns = [\"language\",\"users_count\"]\n",
    "data = [(\"Java\", \"20000\"), (\"Python\", \"100000\"), (\"Scala\", \"3000\")]\n",
    "\n",
    "spark = SparkSession.builder.appName('hack').getOrCreate()\n",
    "rdd = spark.sparkContext.parallelize(data)\n",
    "\n",
    "df = rdd.toDF(columns)\n",
    "\n",
    "columns = [\"language\",\"domain\"]\n",
    "data = [(\"Python\", \"this\"), (\"Java\", \"other\")]\n",
    "d_dd = spark.sparkContext.parallelize(data)\n",
    "d_df = d_dd.toDF(columns)\n",
    "\n",
    "# print(df.columns[0])\n",
    "# print(df.filter(\"language='Python'\").first()[\"users_count\"])\n",
    "\n",
    "def getdomain(p):\n",
    "    domain = d_df.filter(\"language='\"+p+\"'\").select(\"domain\")\n",
    "    if domain.isEmpty():\n",
    "        return None\n",
    "    return domain\n",
    "\n",
    "print(getdomain(\"Python\").domain)\n",
    "\n",
    "df.select(\n",
    "    \"language\",\"users_count\",\n",
    "    lit(getdomain(\"Python\")).alias(\"domain\"))\n",
    "print(df)\n",
    "#\n",
    "# df2 = df.select(\n",
    "#     col(\"language\").alias(\"lang\")\n",
    "# )\n",
    "#\n",
    "# df.join(getdomain(\"Python\"))\n",
    "#\n",
    "# print(df)\n",
    "\n",
    "# print(df2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
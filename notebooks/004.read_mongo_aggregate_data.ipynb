{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/Users/tmillar/dev/repo/hacking-spark-with-mongo/venv/lib/python3.8/site-packages/pyspark/jars/ivy-2.5.0.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /Users/tmillar/.ivy2/cache\n",
      "The jars for the packages stored in: /Users/tmillar/.ivy2/jars\n",
      "org.mongodb.spark#mongo-spark-connector added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-f8c7550e-7f96-45e1-b63c-ca16c32a3b46;1.0\n",
      "\tconfs: [default]\n",
      "\tfound org.mongodb.spark#mongo-spark-connector;10.0.5 in central\n",
      "\tfound org.mongodb#mongodb-driver-sync;4.5.1 in central\n",
      "\t[4.5.1] org.mongodb#mongodb-driver-sync;[4.5.0,4.5.99)\n",
      "\tfound org.mongodb#bson;4.5.1 in central\n",
      "\tfound org.mongodb#mongodb-driver-core;4.5.1 in central\n",
      ":: resolution report :: resolve 1777ms :: artifacts dl 6ms\n",
      "\t:: modules in use:\n",
      "\torg.mongodb#bson;4.5.1 from central in [default]\n",
      "\torg.mongodb#mongodb-driver-core;4.5.1 from central in [default]\n",
      "\torg.mongodb#mongodb-driver-sync;4.5.1 from central in [default]\n",
      "\torg.mongodb.spark#mongo-spark-connector;10.0.5 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   4   |   1   |   0   |   0   ||   4   |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-f8c7550e-7f96-45e1-b63c-ca16c32a3b46\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 4 already retrieved (0kB/6ms)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/11/11 20:29:48 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/11/11 20:29:48 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "\n",
    "database = \"hacking\"\n",
    "collection = \"sales\"\n",
    "connectionString = \"mongodb://127.0.0.1\"\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"aggregate_dataframe\") \\\n",
    "    .config('spark.jars.packages', 'org.mongodb.spark:mongo-spark-connector:10.0.5') \\\n",
    "    .config(\"spark.mongodb.input.uri\", connectionString) \\\n",
    "    .config(\"spark.mongodb.output.uri\", connectionString) \\\n",
    "    .getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "df = spark.read.format(\"mongodb\") \\\n",
    "    .option(\"database\", database) \\\n",
    "    .option(\"collection\", collection) \\\n",
    "    .load()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+-----+--------------------+\n",
      "|Company|Person|Sales|                 _id|\n",
      "+-------+------+-----+--------------------+\n",
      "|   GOOG|   Joe|  200|636d401e920e9fad5...|\n",
      "|   GOOG|  Jane|  120|636d401e920e9fad5...|\n",
      "|   GOOG|  Jake|  340|636d401e920e9fad5...|\n",
      "|   MSFT|   Ace|  600|636d401e920e9fad5...|\n",
      "|   MSFT|  Andy|  123|636d401e920e9fad5...|\n",
      "|   MSFT|George|  222|636d401e920e9fad5...|\n",
      "|     FB|  John|  210|636d401e920e9fad5...|\n",
      "|     FB|   Sam|  999|636d401e920e9fad5...|\n",
      "|   APPL|Johnny|  210|636d401e920e9fad5...|\n",
      "|   APPL|  Mike|  700|636d401e920e9fad5...|\n",
      "|   APPL|  Jane|  100|636d401e920e9fad5...|\n",
      "|   APPL| Chris|   70|636d401e920e9fad5...|\n",
      "+-------+------+-----+--------------------+\n",
      "\n",
      "root\n",
      " |-- Company: string (nullable = true)\n",
      " |-- Person: string (nullable = true)\n",
      " |-- Sales: integer (nullable = true)\n",
      " |-- _id: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.show()\n",
    "df.printSchema()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Group by company, will infer the numeric column for aggregating"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|Company|count|\n",
      "+-------+-----+\n",
      "|   GOOG|    3|\n",
      "|   MSFT|    3|\n",
      "|     FB|    2|\n",
      "|   APPL|    4|\n",
      "+-------+-----+\n",
      "\n",
      "+-------+----------+\n",
      "|Company|avg(Sales)|\n",
      "+-------+----------+\n",
      "|   GOOG|     220.0|\n",
      "|   MSFT|     315.0|\n",
      "|     FB|     604.5|\n",
      "|   APPL|     270.0|\n",
      "+-------+----------+\n",
      "\n",
      "+-------+----------+\n",
      "|Company|max(Sales)|\n",
      "+-------+----------+\n",
      "|   GOOG|       340|\n",
      "|   MSFT|       600|\n",
      "|     FB|       999|\n",
      "|   APPL|       700|\n",
      "+-------+----------+\n",
      "\n",
      "+-------+----------+\n",
      "|Company|avg(Sales)|\n",
      "+-------+----------+\n",
      "|   GOOG|     220.0|\n",
      "|   MSFT|     315.0|\n",
      "|     FB|     604.5|\n",
      "|   APPL|     270.0|\n",
      "+-------+----------+\n",
      "\n",
      "+-------+----------+\n",
      "|Company|sum(Sales)|\n",
      "+-------+----------+\n",
      "|   GOOG|       660|\n",
      "|   MSFT|       945|\n",
      "|     FB|      1209|\n",
      "|   APPL|      1080|\n",
      "+-------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(\"Company\")\n",
    "df.groupBy(\"Company\").count().show()\n",
    "df.groupBy(\"Company\").avg().show()\n",
    "df.groupBy(\"Company\").max().show()\n",
    "df.groupBy(\"Company\").mean().show()\n",
    "df.groupBy(\"Company\").sum().show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Aggregate by column and function"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|sum(Sales)|\n",
      "+----------+\n",
      "|      3894|\n",
      "+----------+\n",
      "\n",
      "+----------+\n",
      "|min(Sales)|\n",
      "+----------+\n",
      "|        70|\n",
      "+----------+\n",
      "\n",
      "+----------+\n",
      "|max(Sales)|\n",
      "+----------+\n",
      "|       999|\n",
      "+----------+\n",
      "\n",
      "+----------+\n",
      "|avg(Sales)|\n",
      "+----------+\n",
      "|     324.5|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.agg({\"Sales\": \"sum\"}).show()\n",
    "df.agg({\"Sales\": \"min\"}).show()\n",
    "df.agg({\"Sales\": \"max\"}).show()\n",
    "df.agg({\"Sales\": \"mean\"}).show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "More specific GroupBy where spark can't infer the numeric column to aggregate\n",
    "\n",
    "_this will have the same results as the GroupBy above because the column here is also the infered column_"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------+\n",
      "|Company|count(Sales)|\n",
      "+-------+------------+\n",
      "|   GOOG|           3|\n",
      "|   MSFT|           3|\n",
      "|     FB|           2|\n",
      "|   APPL|           4|\n",
      "+-------+------------+\n",
      "\n",
      "+-------+----------+\n",
      "|Company|avg(Sales)|\n",
      "+-------+----------+\n",
      "|   GOOG|     220.0|\n",
      "|   MSFT|     315.0|\n",
      "|     FB|     604.5|\n",
      "|   APPL|     270.0|\n",
      "+-------+----------+\n",
      "\n",
      "+-------+----------+\n",
      "|Company|max(Sales)|\n",
      "+-------+----------+\n",
      "|   GOOG|       340|\n",
      "|   MSFT|       600|\n",
      "|     FB|       999|\n",
      "|   APPL|       700|\n",
      "+-------+----------+\n",
      "\n",
      "+-------+----------+\n",
      "|Company|avg(Sales)|\n",
      "+-------+----------+\n",
      "|   GOOG|     220.0|\n",
      "|   MSFT|     315.0|\n",
      "|     FB|     604.5|\n",
      "|   APPL|     270.0|\n",
      "+-------+----------+\n",
      "\n",
      "+-------+----------+\n",
      "|Company|sum(Sales)|\n",
      "+-------+----------+\n",
      "|   GOOG|       660|\n",
      "|   MSFT|       945|\n",
      "|     FB|      1209|\n",
      "|   APPL|      1080|\n",
      "+-------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_grouped = df.groupBy(\"Company\")\n",
    "df_grouped.agg({\"Sales\": \"count\"}).show()\n",
    "df_grouped.agg({\"Sales\": \"avg\"}).show()\n",
    "df_grouped.agg({\"Sales\": \"max\"}).show()\n",
    "df_grouped.agg({\"Sales\": \"mean\"}).show()\n",
    "df_grouped.agg({\"Sales\": \"sum\"}).show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Using builtin SQL functions"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"_pydevd_bundle/pydevd_cython_darwin_38_64.pyx\", line 1589, in _pydevd_bundle.pydevd_cython_darwin_38_64.ThreadTracer.__call__\n",
      "  File \"_pydevd_bundle/pydevd_cython_darwin_38_64.pyx\", line 756, in _pydevd_bundle.pydevd_cython_darwin_38_64.PyDBFrame.trace_dispatch\n",
      "  File \"/Applications/Code/PyCharm.app/Contents/plugins/python/helpers-pro/jupyter_debug/pydev_jupyter_plugin.py\", line 96, in can_not_skip\n",
      "    cell_info = pydb.cell_info\n",
      "AttributeError: 'PyDB' object has no attribute 'cell_info'\n",
      "Traceback (most recent call last):\n",
      "  File \"_pydevd_bundle/pydevd_cython_darwin_38_64.pyx\", line 1589, in _pydevd_bundle.pydevd_cython_darwin_38_64.ThreadTracer.__call__\n",
      "  File \"_pydevd_bundle/pydevd_cython_darwin_38_64.pyx\", line 756, in _pydevd_bundle.pydevd_cython_darwin_38_64.PyDBFrame.trace_dispatch\n",
      "  File \"/Applications/Code/PyCharm.app/Contents/plugins/python/helpers-pro/jupyter_debug/pydev_jupyter_plugin.py\", line 96, in can_not_skip\n",
      "    cell_info = pydb.cell_info\n",
      "AttributeError: 'PyDB' object has no attribute 'cell_info'\n",
      "Traceback (most recent call last):\n",
      "  File \"_pydevd_bundle/pydevd_cython_darwin_38_64.pyx\", line 1589, in _pydevd_bundle.pydevd_cython_darwin_38_64.ThreadTracer.__call__\n",
      "  File \"_pydevd_bundle/pydevd_cython_darwin_38_64.pyx\", line 756, in _pydevd_bundle.pydevd_cython_darwin_38_64.PyDBFrame.trace_dispatch\n",
      "  File \"/Applications/Code/PyCharm.app/Contents/plugins/python/helpers-pro/jupyter_debug/pydev_jupyter_plugin.py\", line 96, in can_not_skip\n",
      "    cell_info = pydb.cell_info\n",
      "AttributeError: 'PyDB' object has no attribute 'cell_info'\n",
      "Traceback (most recent call last):\n",
      "  File \"_pydevd_bundle/pydevd_cython_darwin_38_64.pyx\", line 1589, in _pydevd_bundle.pydevd_cython_darwin_38_64.ThreadTracer.__call__\n",
      "  File \"_pydevd_bundle/pydevd_cython_darwin_38_64.pyx\", line 756, in _pydevd_bundle.pydevd_cython_darwin_38_64.PyDBFrame.trace_dispatch\n",
      "  File \"/Applications/Code/PyCharm.app/Contents/plugins/python/helpers-pro/jupyter_debug/pydev_jupyter_plugin.py\", line 96, in can_not_skip\n",
      "    cell_info = pydb.cell_info\n",
      "AttributeError: 'PyDB' object has no attribute 'cell_info'\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import countDistinct, avg, stddev"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+\n",
      "|count(DISTINCT Sales)|\n",
      "+---------------------+\n",
      "|                   11|\n",
      "+---------------------+\n",
      "\n",
      "+----------+\n",
      "|avg(Sales)|\n",
      "+----------+\n",
      "|     324.5|\n",
      "+----------+\n",
      "\n",
      "+------------------+\n",
      "|Better Column Name|\n",
      "+------------------+\n",
      "|             324.5|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(countDistinct(\"Sales\")).show()\n",
    "df.select(avg(\"Sales\")).show()\n",
    "df.select(avg(\"Sales\").alias(\"Better Column Name\")).show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|           StdDev|\n",
      "+-----------------+\n",
      "|289.4997252314601|\n",
      "+-----------------+\n",
      "\n",
      "+------------------------+\n",
      "|format_number(StdDev, 2)|\n",
      "+------------------------+\n",
      "|                  289.50|\n",
      "+------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import format_number\n",
    "\n",
    "sales_std = df.select(stddev(\"Sales\").alias(\"StdDev\"))\n",
    "sales_std.show()\n",
    "sales_std.select(format_number(\"StdDev\", 2)).show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+-----+--------------------+\n",
      "|Company|Person|Sales|                 _id|\n",
      "+-------+------+-----+--------------------+\n",
      "|   APPL| Chris|   70|636d401e920e9fad5...|\n",
      "|   APPL|  Jane|  100|636d401e920e9fad5...|\n",
      "|   GOOG|  Jane|  120|636d401e920e9fad5...|\n",
      "|   MSFT|  Andy|  123|636d401e920e9fad5...|\n",
      "|   GOOG|   Joe|  200|636d401e920e9fad5...|\n",
      "|     FB|  John|  210|636d401e920e9fad5...|\n",
      "|   APPL|Johnny|  210|636d401e920e9fad5...|\n",
      "|   MSFT|George|  222|636d401e920e9fad5...|\n",
      "|   GOOG|  Jake|  340|636d401e920e9fad5...|\n",
      "|   MSFT|   Ace|  600|636d401e920e9fad5...|\n",
      "|   APPL|  Mike|  700|636d401e920e9fad5...|\n",
      "|     FB|   Sam|  999|636d401e920e9fad5...|\n",
      "+-------+------+-----+--------------------+\n",
      "\n",
      "+-------+------+-----+--------------------+\n",
      "|Company|Person|Sales|                 _id|\n",
      "+-------+------+-----+--------------------+\n",
      "|     FB|   Sam|  999|636d401e920e9fad5...|\n",
      "|   APPL|  Mike|  700|636d401e920e9fad5...|\n",
      "|   MSFT|   Ace|  600|636d401e920e9fad5...|\n",
      "|   GOOG|  Jake|  340|636d401e920e9fad5...|\n",
      "|   MSFT|George|  222|636d401e920e9fad5...|\n",
      "|     FB|  John|  210|636d401e920e9fad5...|\n",
      "|   APPL|Johnny|  210|636d401e920e9fad5...|\n",
      "|   GOOG|   Joe|  200|636d401e920e9fad5...|\n",
      "|   MSFT|  Andy|  123|636d401e920e9fad5...|\n",
      "|   GOOG|  Jane|  120|636d401e920e9fad5...|\n",
      "|   APPL|  Jane|  100|636d401e920e9fad5...|\n",
      "|   APPL| Chris|   70|636d401e920e9fad5...|\n",
      "+-------+------+-----+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.orderBy(\"Sales\").show()\n",
    "df.orderBy(df[\"Sales\"].desc()).show()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}